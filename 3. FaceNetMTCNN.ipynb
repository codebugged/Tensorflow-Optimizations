{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceNetMTCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HImEV_u1aNL7",
        "outputId": "7afddab4-5c87-40da-8c90-3f319dcbe377"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/MRV'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPrXzV7Fa0br",
        "outputId": "5ea77424-ad99-41e1-e36a-cdd54b723288"
      },
      "source": [
        "cd drive/MyDrive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzbF5K5sa3dz",
        "outputId": "6b0ed8da-c1ba-45ce-8f2d-8ccc49e98088"
      },
      "source": [
        "cd MRV"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MRV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YARGWX3Ma4Gq",
        "outputId": "29623950-3950-4af9-b0ff-185bff8f0b03"
      },
      "source": [
        "ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "architecture.py  \u001b[0m\u001b[01;34mencodings\u001b[0m/  \u001b[01;34mFaces\u001b[0m/  \u001b[01;34mmodel\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA6kJq6UbNq3",
        "outputId": "782ce9c6-7fbe-4c85-a019-aa4ddfbccaa8"
      },
      "source": [
        "!pip install -q mtcnn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 3.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1S1g1RQa8Ks"
      },
      "source": [
        "from architecture import *\n",
        "import os\n",
        "import cv2\n",
        "import mtcnn\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPZaE0a2b1jK"
      },
      "source": [
        "face_data = \"Faces/\"\n",
        "required_shape = (160, 160)\n",
        "face_encoder = InceptionResNetV2()\n",
        "path = \"model/facenet_keras_weights.h5\"\n",
        "face_encoder.load_weights(path)\n",
        "face_detector = mtcnn.MTCNN()\n",
        "encodes = []\n",
        "encoding_dict = dict()\n",
        "l2_normalizer = Normalizer(\"l2\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cidow_DUqsxC"
      },
      "source": [
        "## Training Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMnW1KebhGU"
      },
      "source": [
        "def normalize(img):\n",
        "    mean, std = img.mean(), img.std()\n",
        "    return (img - mean) / std"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK1Me3j7bruu"
      },
      "source": [
        "for face_names in os.listdir(face_data):\n",
        "    person_dir = os.path.join(face_data, face_names)\n",
        "\n",
        "    for image_name in os.listdir(person_dir):\n",
        "        image_path = os.path.join(person_dir, image_name)\n",
        "\n",
        "        img_BGR = cv2.imread(image_path)\n",
        "        img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        x = face_detector.detect_faces(img_RGB)\n",
        "        x1, y1, width, height = x[0][\"box\"]\n",
        "        x1, y1 = abs(x1), abs(y1)\n",
        "        x2, y2 = x1 + width, y1 + height\n",
        "        face = img_RGB[y1:y2, x1:x2]\n",
        "\n",
        "        face = normalize(face)\n",
        "        face = cv2.resize(face, required_shape)\n",
        "        face_d = np.expand_dims(face, axis=0)\n",
        "        encode = face_encoder.predict(face_d)[0]\n",
        "        encodes.append(encode)\n",
        "\n",
        "    if encodes:\n",
        "        encode = np.sum(encodes, axis=0)\n",
        "        encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]\n",
        "        encoding_dict[face_names] = encode"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9P6l5W3lpo5"
      },
      "source": [
        "path = \"encodings/encodings.pkl\"\n",
        "with open(path, \"wb\") as file:\n",
        "    pickle.dump(encoding_dict, file)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lU8IXipq_Mo"
      },
      "source": [
        "## Detection Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsNTIVZiqxXP"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mtcnn\n",
        "from architecture import *\n",
        "from train import normalize, l2_normalizer\n",
        "from scipy.spatial.distance import cosine\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYng3MyCrDJE"
      },
      "source": [
        "confidence_t = 0.99\n",
        "recognition_t = 0.5\n",
        "required_size = (160, 160)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QygX2uD_rI_t"
      },
      "source": [
        "def get_face(img, box):\n",
        "    x1, y1, width, height = box\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    face = img[y1:y2, x1:x2]\n",
        "    return face, (x1, y1), (x2, y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2Qke4xrM-t"
      },
      "source": [
        "def get_encode(face_encoder, face, size):\n",
        "    face = normalize(face)\n",
        "    face = cv2.resize(face, size)\n",
        "    encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
        "    return encode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQiroBErQNM"
      },
      "source": [
        "def load_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        encoding_dict = pickle.load(f)\n",
        "    return encoding_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCboMUTPrTpc"
      },
      "source": [
        "def detect(img, detector, encoder, encoding_dict):\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = detector.detect_faces(img_rgb)\n",
        "    for res in results:\n",
        "        if res[\"confidence\"] < confidence_t:\n",
        "            continue\n",
        "        face, pt_1, pt_2 = get_face(img_rgb, res[\"box\"])\n",
        "        encode = get_encode(encoder, face, required_size)\n",
        "        encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n",
        "        name = \"unknown\"\n",
        "\n",
        "        distance = float(\"inf\")\n",
        "        for db_name, db_encode in encoding_dict.items():\n",
        "            dist = cosine(db_encode, encode)\n",
        "            if dist < recognition_t and dist < distance:\n",
        "                name = db_name\n",
        "                distance = dist\n",
        "\n",
        "        if name == \"unknown\":\n",
        "            cv2.rectangle(img, pt_1, pt_2, (0, 0, 255), 2)\n",
        "            cv2.putText(img, name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
        "        else:\n",
        "            cv2.rectangle(img, pt_1, pt_2, (0, 255, 0), 2)\n",
        "            cv2.putText(\n",
        "                img,\n",
        "                name + f\"__{distance:.2f}\",\n",
        "                (pt_1[0], pt_1[1] - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1,\n",
        "                (0, 200, 200),\n",
        "                2,\n",
        "            )\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV8Ixw-TrXkS"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    required_shape = (160, 160)\n",
        "    face_encoder = InceptionResNetV2()\n",
        "    path_m = \"model/facenet_keras_weights.h5\"\n",
        "    face_encoder.load_weights(path_m)\n",
        "    encodings_path = \"encodings/encodings.pkl\"\n",
        "    face_detector = mtcnn.MTCNN()\n",
        "    encoding_dict = load_pickle(encodings_path)\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print(\"CAM NOT OPEN\")\n",
        "            break\n",
        "\n",
        "        frame = detect(frame, face_detector, face_encoder, encoding_dict)\n",
        "\n",
        "        cv2.imshow(\"camera\", frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}