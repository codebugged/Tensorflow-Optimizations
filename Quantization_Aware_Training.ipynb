{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantization_Aware_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWkwmc1UbSlW",
        "outputId": "de335b5b-535b-460e-c762-77d32bbd6a02"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 15 09:49:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjc81l8_bc1J",
        "outputId": "93251596-1de4-4ac9-8b68-abdcd6419e82"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install -q tf-nightly\n",
        "!pip install -qq tensorflow-model-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "\u001b[K     |████████████████████████████████| 453.3MB 41kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 45.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9MB 32.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 59.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9MB 26.2MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 174kB 25.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqBkIqcAdNhF",
        "outputId": "f9dbd3bc-816b-4b68-9148-949cfa3a6e2f"
      },
      "source": [
        "!wget https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \n",
        "!wget https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 09:58:22--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.13.80, 172.217.13.240, 172.217.15.80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.13.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200682221 (191M) [application/zip]\n",
            "Saving to: ‘rps.zip’\n",
            "\n",
            "rps.zip             100%[===================>] 191.38M   129MB/s    in 1.5s    \n",
            "\n",
            "2021-05-15 09:58:24 (129 MB/s) - ‘rps.zip’ saved [200682221/200682221]\n",
            "\n",
            "--2021-05-15 09:58:24--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.73.208, 142.250.65.80, 142.251.33.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.73.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29516758 (28M) [application/zip]\n",
            "Saving to: ‘rps-test-set.zip’\n",
            "\n",
            "rps-test-set.zip    100%[===================>]  28.15M  46.1MB/s    in 0.6s    \n",
            "\n",
            "2021-05-15 09:58:24 (46.1 MB/s) - ‘rps-test-set.zip’ saved [29516758/29516758]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSJZ_DuEdQfg"
      },
      "source": [
        "!unzip -q rps.zip\n",
        "!unzip -qq rps-test-set.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eQ9UDv0dSr_",
        "outputId": "fff05101-619b-4963-f485-b2f0318a09c5"
      },
      "source": [
        "from imutils import paths\n",
        "from pprint import pprint\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import re \n",
        "\n",
        "import os\n",
        "from sys import getsizeof\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sys import getsizeof\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0-dev20210514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrwKNJPQdVER"
      },
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File Size: ' + str(round(size/1024, 3)) + 'Kilobytes')\n",
        "    elif unit == 'MB':\n",
        "        return print('File Size: ' + str(round(size/(1024*1024), 3)) + 'Megabytes')\n",
        "    else:\n",
        "        return print('File Size: ' + str(size) + 'bytes')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uie-8xtdXqD"
      },
      "source": [
        "train_dir='rps/'\n",
        "test_dir='rps-test-set/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "ZyyldUEedZWl",
        "outputId": "9c8da41d-896a-49fe-b035-a135af8733b4"
      },
      "source": [
        "dim1 = []\n",
        "dim2 = []\n",
        "for image_filename in os.listdir(train_dir+'paper'):\n",
        "    \n",
        "    img = mpimg.imread(train_dir+'paper'+'/'+image_filename)\n",
        "    d1,d2,colors = img.shape\n",
        "    dim1.append(d1)\n",
        "    dim2.append(d2)\n",
        "\n",
        "sns.jointplot(dim1,dim2)\n",
        "\n",
        "print(\"Height: \",np.mean(dim1))\n",
        "print(\"Width: \",np.mean(dim2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Height:  300.0\n",
            "Width:  300.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGoCAYAAADB4nuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXNUlEQVR4nO3cf6zddX348ecLbksRLM3gotL2u9ZoZxonZVSCskWtwXR1ARMlc4uORDYMMsMPv264r18Ttu8f6vYV/WMJIxRCpps4ZRMJm3ahagyu5QJtoRRZYW794eyFLxVdbKH0tT/Ou3C833N7z23v7Wlf5/lITvicz+d9Puf9trfn2c85xxuZiSRJFZw06AlIkjRTjJokqQyjJkkqw6hJksowapKkMkYGPYFp8quakoZZDHoCxzuv1CRJZRg1SVIZJ9rbj0ds4eL/we6dOwY9DUlD7pxFi9m14z8GPY2y4gT7jSJHPNmI4Lf/6v6ZnIskTdudH34rR/G662dqU/DtR0lSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllRGYOeg59i4h/As4a9Dym4Szg6UFP4hhwnfUMy1pPtHU+nZmrBz2J49kJFbUTTUSMZebKQc9jtrnOeoZlrcOyzmHi24+SpDKMmiSpDKM2u24Z9ASOEddZz7CsdVjWOTT8TE2SVIZXapKkMoyaJKkMoyZJKsOoSZLKMGqSpDJOqKitXr06AW/evHkb1lvfir9eTuqEitrTT59Iv6JNkgZnWF8vT6ioSZJ0OEZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGSODnoAkaeZt2bKFiBj0NGbUOYsWs2vHfxx2jFGTpIJeeOEFfvuv7h/0NGbUnR9+65RjfPtRklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGVNGLSLmRcTGiNgcEVsj4sa2f2lEbIiI7RFxZ0TMbftPafe3t+NLDnPukyPi4Yi4Z6YWJEkaXv1cqe0HVmXmucAKYHVEXAh8BrgpM18HPAtc0cZfATzb9t/Uxk3mGmDbkU5ekqRuU0YtO37W7s5ptwRWAV9t++8A3tO2L233acffGREx8bwRsQh4N3DrEc9ekqQufX2m1t4m3ATsAdYBTwJ7M/NAG7ITWNi2FwI7ANrxnwBn9jjt54E/Ag5O8dxXRsRYRIyNj4/3M11JGkrdr5eDnsug9BW1zHwxM1cAi4ALgDcczZNGxG8BezLzwT6e+5bMXJmZK0dHR4/maSWptO7Xy0HPZVCm9e3HzNwLrAfeAiyIiJF2aBGwq23vAhYDtONnAM9MONVFwCUR8UPgy8CqiPjikSxAkqRD+vn242hELGjbpwIX0/lyx3rgfW3Y5cDX2/bd7T7t+H2Zmd3nzMxPZOaizFwCvL+N+cBRrkWSNOT6uVJ7DbA+IrYADwDrMvMe4I+B6yNiO53PzNa28WuBM9v+64EbACLinIi4d6YXIEnSISNTDcjMLcB5PfY/RefztYn79wGX9di/G1jTY/+3gW/3NVtJkg7D3ygiSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSypgyahExLyI2RsTmiNgaETe2/UsjYkNEbI+IOyNibtt/Sru/vR1f0uOciyNifUQ81s55zUwvTJI0fPq5UtsPrMrMc4EVwOqIuBD4DHBTZr4OeBa4oo2/Ani27b+pjZvoAPCxzFwOXAhcHRHLj24pkqRhN2XUsuNn7e6cdktgFfDVtv8O4D1t+9J2n3b8nRERE875o8x8qG3/FNgGLDyKdUiS1N9nahFxckRsAvYA64Angb2ZeaAN2cnLUVoI7ABox38CnHmYcy8BzgM2TH/6kiS9rK+oZeaLmbkCWARcALxhJp48Ik4HvgZcm5nPTTLmyogYi4ix8fHxmXhaSSqp+/Vy0HMZlGl9+zEz9wLrgbcACyJipB1aBOxq27uAxQDt+BnAMxPPFRFz6ATtS5l512Ge85bMXJmZK0dHR6czXUkaKt2vl4Oey6D08+3H0YhY0LZPBS6m8xnYeuB9bdjlwNfb9t3tPu34fZmZE84ZwFpgW2Z+7mgXIUkS9Hel9hpgfURsAR4A1mXmPcAfA9dHxHY6n5mtbePXAme2/dcDNwBExDkRcW8bcxHwQWBVRGxqtzUztipJ0lAamWpAZm6h80WOifufovP52sT9+4DLeuzfDaxp298DYuIYSZKOhr9RRJJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZRg1SVIZRk2SVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEllGDVJUhlGTZJUhlGTJJVh1CRJZUwZtYiYFxEbI2JzRGyNiBvb/qURsSEitkfEnRExt+0/pd3f3o4vmeS8qyPiB23cDTO5KGkm7f35Pjb+2zN8Y/NuNv7bM+z9+b5BT0nSJPq5UtsPrMrMc4EVwOqIuBD4DHBTZr4OeBa4oo2/Ani27b+pjfsFEXEy8JfAbwLLgd+JiOVHuxhppu39+T6+9eg4v3fbRj76tw/ze7dt5FuPjhs26Tg1ZdSy42ft7px2S2AV8NW2/w7gPW370nafdvydERETTnsBsD0zn8rM54Evt8dJx5Un/vO/+NTdj7LvhYMA7HvhIJ+6+1Ge+M//GvDMJPXS12dqEXFyRGwC9gDrgCeBvZl5oA3ZCSxs2wuBHQDt+E+AMyec8qUxPR4/8bmvjIixiBgbHx/vZ7rSjPnxc/tfCtoh+144yI+f2z+gGUmT6369HPRcBqWvqGXmi5m5AlhE5yrrDbM6q1987lsyc2VmrhwdHT1WTysB8Kr5pzBvzi/+NZk35yReNf+UAc1Imlz36+Wg5zIo0/r2Y2buBdYDbwEWRMRIO7QI2NW2dwGLAdrxM4BnJpzqpTE9Hi8dN5a9+jT+9JI3vhS2eXNO4k8veSPLXn3agGcmqZeRqQZExCjwQmbujYhTgYvpfPljPfA+Op+HXQ58vT3k7nb/++34fZmZE077APD6iFhKJ2bvB3736JcjzawFp87jXW8cZclZF/Dj5/bzqvmnsOzVp7Hg1HmDnpqkHqaMGvAa4I72jcWTgK9k5j0R8Rjw5Yj4P8DDwNo2fi3w1xGxHfh/dIJFRJwD3JqZazLzQET8IfBN4GTgtszcOqMrk2bIglPnccFSIyadCKaMWmZuAc7rsf8pOp+vTdy/D7isx/7dwJqu+/cC905zvpIkTcrfKCJJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKmDJqEbE4ItZHxGMRsTUirmn7z42I70fEIxHxjYiY3/bPjYjb2/7NEfH2Sc67IiL+JSI2RcRYRFwwoyuTJA2dfq7UDgAfy8zlwIXA1RGxHLgVuCEzfxX4e+DjbfwfALT9FwP/NyJ6Pc9ngRszcwXwqXZfkqQjNmXUMvNHmflQ2/4psA1YCCwDvtuGrQPe27aXA/e18XuAvcDKXqcG5rftM4DdR7YESZI6pvWZWkQsAc4DNgBbgUvbocuAxW17M3BJRIxExFLg/K5j3a4F/jwidgB/AXxikue8sr09OTY+Pj6d6UrSUOl+vRz0XAal76hFxOnA14BrM/M54EPARyLiQeCVwPNt6G3ATmAM+DxwP/Bij1NeBVyXmYuB64C1vZ43M2/JzJWZuXJ0dLTf6UrS0Ol+vRz0XAZlpJ9BETGHTtC+lJl3AWTm48C72vFlwLvb/gN0InXosfcDT/Q47eXANW377+h8RidJ0hHr59uPQecqaltmfq5r/9ntvycBnwRubvdfERGnte2LgQOZ+ViPU+8G3ta2VwH/ehTrkCSpryu1i4APAo9ExKa270+A10fE1e3+XcDtbfts4JsRcRDY1R4LQETcCtycmWN0viX5hYgYAfYBVx7tYiRJw23KqGXm94CY5PAXeoz/IfArk5zr9yec9/y+ZilJUh/8jSKSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpjCmjFhGLI2J9RDwWEVsj4pq2/9yI+H5EPBIR34iI+W3/3Ii4ve3fHBFvP8y5PxoRj7fzfnbGViVJGkojfYw5AHwsMx+KiFcCD0bEOuBW4H9m5nci4kPAx4H/DfwBQGb+akScDfxjRLw5Mw92nzQi3gFcCpybmfvbWEmSjtiUV2qZ+aPMfKht/xTYBiwElgHfbcPWAe9t28uB+9r4PcBeYGWPU18FfDoz93eNlSTpiE3rM7WIWAKcB2wAttK50gK4DFjctjcDl0TESEQsBc7vOtZtGfAbEbEhIr4TEW+e5DmvjIixiBgbHx+fznQlaah0v14Oei6D0nfUIuJ04GvAtZn5HPAh4CMR8SDwSuD5NvQ2YCcwBnweuB94sccpR4BfAi6k89blVyIiJg7KzFsyc2VmrhwdHe17YZI0bLpfLwc9l0Hp5zM1ImIOnaB9KTPvAsjMx4F3tePLgHe3/QeA67oeez/wRI/T7gTuyswENkbEQeAswMsxSdIR6efbjwGsBbZl5ue69p/d/nsS8Eng5nb/FRFxWtu+GDiQmY/1OPU/AO9o45YBc4Gnj2o1kqSh1s+V2kXAB4FHImJT2/cnwOsj4up2/y7g9rZ9NvDNduW1qz0WgIi4Fbg5M8fovE15W0Q8Suety8vbVZskSUdkyqhl5veA/++zruYLPcb/EPiVSc71+13bzwMf6GuWkiT1wd8oIkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpDKMmSSrDqEmSyjBqkqQyjJokqYyRQU9AkjTz5syZw50ffuugpzGjzlm0eMoxRk2SCnrTm97E2NjYoKdxzPn2oySpDKMmSSrDqEmSyjBqkqQyjJokqQyjJkkqw6hJksowapKkMoyaJKkMoyZJKsOoSZLKMGqSpDKMmiSpjMjMQc+hbxExDvz7oOcxDWcBTw96EseA66xnWNZ6oq3z6cxc3c/AiPinfsdWckJF7UQTEWOZuXLQ85htrrOeYVnrsKxzmPj2oySpDKMmSSrDqM2uWwY9gWPEddYzLGsdlnUODT9TkySV4ZWaJKkMoyZJKsOo9SEiFkfE+oh4LCK2RsQ1bf+5EfH9iHgkIr4REfPb/rkRcXvbvzki3n6Yc380Ih5v5/3sMVrSpGZrrRGxIiL+JSI2RcRYRFxwDJfVaz7zImJjm/PWiLix7V8aERsiYntE3BkRc9v+U9r97e34kknOuzoiftDG3XDsVtTbbKxzsp+RQZutP9M29uSIeDgi7jk2q9ERy0xvU9yA1wC/1rZfCTwBLAceAN7W9n8I+LO2fTVwe9s+G3gQOKnHed8B/DNwyqGxhdf6LeA32/Ya4NsDXmcAp7ftOcAG4ELgK8D72/6bgava9keAm9v2+4E7e5zzZOBJ4LXAXGAzsLzgOnv+jBwHP7szvtauc18P/A1wz6DX6e3wN6/U+pCZP8rMh9r2T4FtwEJgGfDdNmwd8N62vRy4r43fA+wFev0fPK8CPp2Z+7vGDtQsrjWB+W37DGD3bMy/X9nxs3Z3TrslsAr4att/B/Cetn1pu087/s6IiAmnvQDYnplPZebzwJfb4wZmNtZ5mJ+RgZqlP1MiYhHwbuDWWZq6ZpBRm6b2FsV5dP4VuJWXX7QuAxa37c3AJRExEhFLgfO7jnVbBvxGe+vjOxHx5tmc+3TN8FqvBf48InYAfwF8YvZm3p/2ltImYA+dUD8J7M3MA23ITl5+sV4I7ABox38CnDnhlC+N6fH4gZmFdXafewkv/4wM3Cyt9fPAHwEHZ3HqmiFGbRoi4nTga8C1mfkcnbfhPhIRD9J5G+b5NvQ2On95xuj8hbgfeLHHKUeAX6LzFsnHga/0+pfiIMzCWq8CrsvMxcB1wNrZXcHUMvPFzFwBLKJzlfWGAU9pVszWOnv8jAzcTK81In4L2JOZD87E/DT7RgY9gRNFRMyh8xf4S5l5F0BmPg68qx1fRuctikP/6ruu67H30/ncYaKdwF2ZmcDGiDhI5xesjs/iUqY0S2u9HDj0hYK/4zh6Kycz90bEeuAtwIKIGGnrWgTsasN20bkC3RkRI3TeQn1mwqkOjTmk+/EDN4Pr7PkzcjyZwbVeROediDXAPGB+RHwxMz9wTBaiafNKrQ/t6mktsC0zP9e1/+z235OAT9L5EJqIeEVEnNa2LwYOZOZjPU79D3S+LHIoFHMZ8G8Mn8W17gbe1rZXAf86a4voQ0SMRsSCtn0qcDGdz4bWA+9rwy4Hvt627273acfva/8Y6fYA8Pr2bbu5dL58cPfsrWJqs7HOyX5GBm021pqZn8jMRZm5hM6f530G7Tg36G+qnAg34NfpfOC8BdjUbmvoXHk80W6f5uXf0LIE+AGdv1D/DPxy17luBVa27bnAF4FHgYeAVYXX+ut0vhm5mc7nL+cPeJ1vAh5u63wU+FTb/1pgI7CdzhXloW+mzmv3t7fjr237zwHu7Trvmva/0ZPA/zoO/jxnfJ2T/YxUXOuE878dv/143N/8NVmSpDJ8+1GSVIZRkySVYdQkSWUYNUlSGUZNklSGUZMklWHUJEll/DeGxsDvgxGCHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqlSW5zJdask",
        "outputId": "e1d09600-a3ad-4a40-fd02-9703ae219cc7"
      },
      "source": [
        "image_paths = list(paths.list_images(\"rps\"))\n",
        "np.random.shuffle(image_paths)\n",
        "image_paths[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rps/paper/paper07-077.png',\n",
              " 'rps/rock/rock05ck01-115.png',\n",
              " 'rps/rock/rock02-034.png',\n",
              " 'rps/paper/paper04-038.png',\n",
              " 'rps/scissors/scissors01-076.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEtD1Gu6dc6_",
        "outputId": "2569b984-26dc-47a1-d3e1-19fa83c8bc28"
      },
      "source": [
        "labels = []\n",
        "for image_path in image_paths:\n",
        "    label = image_path.split(\"/\")[1]\n",
        "    labels.append(label)\n",
        "class_count = Counter(labels) \n",
        "pprint(class_count)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'paper': 840, 'rock': 840, 'scissors': 840})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4GMV8oNdfCA"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "IMG_SIZE = 150\n",
        "NUM_CLASSES=3"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5LntKRldgrr",
        "outputId": "d775e510-eb2e-4496-8a8d-56bafd44be68"
      },
      "source": [
        "training_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\ttrain_dir,\n",
        "\ttarget_size=(IMG_SIZE,IMG_SIZE),\n",
        "\tclass_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\ttest_dir,\n",
        "\ttarget_size=(IMG_SIZE,IMG_SIZE),\n",
        "\tclass_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2520 images belonging to 3 classes.\n",
            "Found 372 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hysiXIqpdifC",
        "outputId": "6a3fe399-a8c0-4161-8410-fc4900915d70"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'paper': 0, 'rock': 1, 'scissors': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nISiM7Ildk5H"
      },
      "source": [
        "def training_model():\n",
        "    model = Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        # The second convolution\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        # The third convolution\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        # The fourth convolution\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        # Flatten the results to feed into a DNN\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # 512 neuron hidden layer\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')                       \n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23dvT4RLdmfP",
        "outputId": "da483649-6889-425a-f4df-5a9816a572dd"
      },
      "source": [
        "model = training_model()\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 3,473,475\n",
            "Trainable params: 3,473,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sisgfz4NdoBa",
        "outputId": "4b138afb-4a8b-48b7-bd01-232e69452088"
      },
      "source": [
        "#Compile the Model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "#Train the Model\n",
        "history = model.fit(train_generator, epochs=EPOCHS, steps_per_epoch=20, validation_data = validation_generator, validation_steps=3, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 153s 8s/step - loss: 1.7003 - accuracy: 0.3536 - val_loss: 1.0951 - val_accuracy: 0.3333\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 153s 8s/step - loss: 1.0960 - accuracy: 0.3595 - val_loss: 1.0696 - val_accuracy: 0.4785\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 150s 7s/step - loss: 1.1020 - accuracy: 0.4036 - val_loss: 1.0408 - val_accuracy: 0.5242\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 149s 7s/step - loss: 1.0467 - accuracy: 0.4556 - val_loss: 0.8936 - val_accuracy: 0.6102\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 149s 7s/step - loss: 1.0187 - accuracy: 0.4964 - val_loss: 0.8999 - val_accuracy: 0.6156\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 148s 7s/step - loss: 0.9641 - accuracy: 0.5206 - val_loss: 0.8297 - val_accuracy: 0.6774\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 147s 7s/step - loss: 0.9196 - accuracy: 0.5690 - val_loss: 0.7126 - val_accuracy: 0.8091\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.8697 - accuracy: 0.6151"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bQ-2yc3dqCX"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=1)\n",
        "print('Test Accuracy:', test_acc)\n",
        "print('Test Loss:', test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5WssR8tduTC"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.title('accuracy plot - train vs test')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n",
        "plt.title('loss plot - training vs validation')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW7vmg-udvlW"
      },
      "source": [
        "model.save('rps_model')\n",
        "model.save('rps.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trIIR67YdxPF"
      },
      "source": [
        "!du -lh rps_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnDJWvjdy3R"
      },
      "source": [
        "convert_bytes(get_file_size('rps.h5'), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnHclVShd0To"
      },
      "source": [
        "!tar cvf rps.tar.gz rps_model rps.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aapI0QL_d12b"
      },
      "source": [
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljzhXGl6d3w3"
      },
      "source": [
        "q_aware_model.fit(train_generator, epochs=20, validation_data = validation_generator, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtqJjwctd5j7"
      },
      "source": [
        "q_aware_model_loss, q_aware_model_accuracy = q_aware_model.evaluate(validation_generator, verbose=1)\n",
        "print('Quant Test Accuracy:', q_aware_model_accuracy)\n",
        "print('Quant Test Loss:', q_aware_model_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ZWBnBdd7WI"
      },
      "source": [
        "TF_LITE_MODEL_FILE_NAME = 'tf_lite_model_rps.tflite'\n",
        "\n",
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tf_lite_converter.convert()\n",
        "\n",
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LSsnz7Pd8p9"
      },
      "source": [
        "TF_LITE_QUANT_MODEL_FILE_NAME = 'tf_lite_quant_model_rps.tflite'\n",
        "\n",
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = tf_lite_converter.convert()\n",
        "\n",
        "tflite_model_name = TF_LITE_QUANT_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSqEkgbNd98A"
      },
      "source": [
        "convert_bytes(get_file_size('tf_lite_model_rps.tflite'), \"MB\")\n",
        "convert_bytes(get_file_size('tf_lite_quant_model_rps.tflite'), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0G7Tm75d_ac"
      },
      "source": [
        "images, labels = (next(iter(validation_generator)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfyPM5WeAts"
      },
      "source": [
        "print(images.shape)\n",
        "print(images.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6jXCgMleB_q"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4LBN8ileDPT"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (128, 150, 150, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (128, 3))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCAKLrUeEqM"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], images)\n",
        "interpreter.invoke()\n",
        "\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
        "expected_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "acc = accuracy_score(prediction_classes, expected_classes)\n",
        "print('Test accuracy TFLITE model :', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfiMd06geGgz"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_QUANT_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg07MTHPeIMt"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (128, 150, 150, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (128, 3))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNQOCFBNeJhH"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], images)\n",
        "interpreter.invoke()\n",
        "\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
        "expected_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "acc = accuracy_score(prediction_classes, expected_classes)\n",
        "print('Test accuracy TFLITE model :', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6JEdr41eNZw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}